{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Skript wird nicht auf ein sequentielles Model (Sequential) gesetzt, sondern auf ein Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from typing import Tuple\n",
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from scipy.stats import randint\n",
    "from scipy.stats import uniform\n",
    "\n",
    "from tf_utils.Cifar10DataAdvanced import CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGS_DIR = os.path.abspath('C:/Selbststudium/Udemy/Udemy_Tensorflow/logs/Cifar/')\n",
    "if not os.path.exists(LOGS_DIR):\n",
    "    os.mkdir(LOGS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(\n",
    "    img_shape: Tuple[int, int, int],\n",
    "    num_classes: int,\n",
    "    optimizer: tf.keras.optimizers.Optimizer,\n",
    "    learning_rate: float,\n",
    "    filter_block_1: int,\n",
    "    kernel_size_block_1: int,\n",
    "    filter_block_2: int,\n",
    "    kernel_size_block_2: int,\n",
    "    filter_block_3: int,\n",
    "    kernel_size_block_3: int,\n",
    "    dense_layer_size: int\n",
    ") -> Model:\n",
    "    input_img = Input(shape=img_shape)\n",
    "\n",
    "    x = Conv2D(filters=filter_block_1, kernel_size=kernel_size_block_1, padding='same')(input_img)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(filters=filter_block_1, kernel_size=kernel_size_block_1, padding='same')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "\n",
    "    x = Conv2D(filters=filter_block_2, kernel_size=kernel_size_block_2, padding='same')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(filters=filter_block_2, kernel_size=kernel_size_block_2, padding='same')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "\n",
    "    x = Conv2D(filters=filter_block_3, kernel_size=kernel_size_block_3, padding='same')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(filters=filter_block_3, kernel_size=kernel_size_block_3, padding='same')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(units=dense_layer_size)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dense(units=num_classes)(x)\n",
    "    y_pred = Activation('softmax')(x)\n",
    "\n",
    "    # Jetzt muss noch ein Modell Objekt mit eben obiger Struktur erstellt werden\n",
    "    model = Model(\n",
    "        inputs = [input_img],\n",
    "        outputs = [y_pred]\n",
    "    )\n",
    "    \n",
    "    opt = optimizer(learning_rate=learning_rate)\n",
    "    \n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy', # wird bei Kategorie-Problemen mit mehr als 2 Klassen genommen\n",
    "        optimizer=opt,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = CIFAR10()\n",
    "\n",
    "train_dataset = data.get_train_set()\n",
    "val_dataset = data.get_val_set()\n",
    "\n",
    "epochs = 30\n",
    "batch_size = 256\n",
    "\n",
    "param_distribution={\n",
    "    \"optimizer\": [Adam, RMSprop],\n",
    "    \"learning_rate\": uniform(0.001, 0.0001),\n",
    "    \"filter_block_1\": randint(16, 64),\n",
    "    \"kernel_size_block_1\": randint(3, 7),\n",
    "    \"filter_block_2\": randint(16, 64),\n",
    "    \"kernel_size_block_2\": randint(3, 7),\n",
    "    \"filter_block_3\": randint(16, 64),\n",
    "    \"kernel_size_block_3\": randint(3, 7),\n",
    "    \"dense_layer_size\": randint(128, 1024)\n",
    "}\n",
    "\n",
    "results = {\n",
    "    'best_score': -np.inf,\n",
    "    'best_params': {},\n",
    "    'val_scores': [],\n",
    "    'params': []\n",
    "}\n",
    "\n",
    "n_models = 32\n",
    "dist = ParameterSampler(param_distribution, n_iter=n_models)\n",
    "print(f'Parameter combinations in total: {len(dist)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, comb in enumerate(dist):\n",
    "    print(f'Running combination: {idx}')\n",
    "\n",
    "    model = build_model(\n",
    "        data.img_shape,\n",
    "        data.num_classes,\n",
    "        **comb\n",
    "    )\n",
    "\n",
    "    model_log_dir = os.path.join(LOGS_DIR, f\"modelRand{idx}\")\n",
    "    if os.path.exists(model_log_dir):\n",
    "        shutil.rmtree(model_log_dir)\n",
    "        os.mkdir(model_log_dir)\n",
    "\n",
    "    tb_callback = TensorBoard(\n",
    "        log_dir=model_log_dir,\n",
    "        histogram_freq=0,\n",
    "        profile_batch=0\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        train_dataset,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        verbose=1,\n",
    "        validation_data=val_dataset,\n",
    "        callbacks=[tb_callback]\n",
    "    )\n",
    "\n",
    "    val_accuracy = model.evaluate(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        verbose=0\n",
    "    )[1]\n",
    "\n",
    "    results['val_scores'].append(val_accuracy)\n",
    "    results['params'].append(comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run_idx = np.argmax(results['val_scores'])\n",
    "results['best_score'] = results['val_scores'][best_run_idx]\n",
    "results['best_params'] = results['params'][best_run_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best score: {results['best_score']} using params: {results['best_params']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = results['val_scores']\n",
    "params = results['params']\n",
    "\n",
    "for score, param in zip(scores, params):\n",
    "    print(f'Score: {score} with param: {param}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "683035455952fa0c5c07396da2eac07ae1d76897e4164c7dcbe8556e60afc848"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('udemy_tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
