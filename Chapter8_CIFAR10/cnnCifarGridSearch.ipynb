{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Skript wird nicht auf ein sequentielles Model (Sequential) gesetzt, sondern auf ein Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from typing import Tuple\n",
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "from tf_utils.Cifar10DataAdvanced import CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGS_DIR = os.path.abspath('C:/Selbststudium/Udemy/Udemy_Tensorflow/logs/Cifar/')\n",
    "if not os.path.exists(LOGS_DIR):\n",
    "    os.mkdir(LOGS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(\n",
    "    img_shape: Tuple[int, int, int],\n",
    "    num_classes: int,\n",
    "    optimizer: tf.keras.optimizers.Optimizer,\n",
    "    learning_rate: float,\n",
    "    filter_block_1: int,\n",
    "    kernel_size_block_1: int,\n",
    "    filter_block_2: int,\n",
    "    kernel_size_block_2: int,\n",
    "    filter_block_3: int,\n",
    "    kernel_size_block_3: int,\n",
    "    dense_layer_size: int\n",
    ") -> Model:\n",
    "    input_img = Input(shape=img_shape)\n",
    "\n",
    "    x = Conv2D(filters=filter_block_1, kernel_size=kernel_size_block_1, padding='same')(input_img)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(filters=filter_block_1, kernel_size=kernel_size_block_1, padding='same')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "\n",
    "    x = Conv2D(filters=filter_block_2, kernel_size=kernel_size_block_2, padding='same')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(filters=filter_block_2, kernel_size=kernel_size_block_2, padding='same')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "\n",
    "    x = Conv2D(filters=filter_block_3, kernel_size=kernel_size_block_3, padding='same')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(filters=filter_block_3, kernel_size=kernel_size_block_3, padding='same')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(units=dense_layer_size)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dense(units=num_classes)(x)\n",
    "    y_pred = Activation('softmax')(x)\n",
    "\n",
    "    # Jetzt muss noch ein Modell Objekt mit eben obiger Struktur erstellt werden\n",
    "    model = Model(\n",
    "        inputs = [input_img],\n",
    "        outputs = [y_pred]\n",
    "    )\n",
    "    \n",
    "    opt = optimizer(learning_rate=learning_rate)\n",
    "    \n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy', # wird bei Kategorie-Problemen mit mehr als 2 Klassen genommen\n",
    "        optimizer=opt,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter combinations in total: 32\n"
     ]
    }
   ],
   "source": [
    "data = CIFAR10()\n",
    "\n",
    "train_dataset = data.get_train_set()\n",
    "val_dataset = data.get_val_set()\n",
    "\n",
    "epochs = 30\n",
    "batch_size = 256\n",
    "\n",
    "param_grid={\n",
    "    \"optimizer\": [Adam, RMSprop],\n",
    "    \"learning_rate\": [0.001],\n",
    "    \"filter_block_1\": [32],\n",
    "    \"kernel_size_block_1\": [3, 5],\n",
    "    \"filter_block_2\": [32, 64],\n",
    "    \"kernel_size_block_2\": [3, 5],\n",
    "    \"filter_block_3\": [64, 128],\n",
    "    \"kernel_size_block_3\": [7],\n",
    "    \"dense_layer_size\": [512]\n",
    "}\n",
    "\n",
    "results = {\n",
    "    'best_score': -np.inf,\n",
    "    'best_params': {},\n",
    "    'val_scores': [],\n",
    "    'params': []\n",
    "}\n",
    "\n",
    "grid = ParameterGrid(param_grid)\n",
    "print(f'Parameter combinations in total: {len(grid)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running combination: 0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unrecognized arguments in `TensorBoard` Callback: {'print_batch'}. Supported kwargs are: {'embeddings_data', 'embeddings_layer_names', 'write_grads', 'batch_size'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_37144/367931839.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_log_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     tb_callback = TensorBoard(\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mlog_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_log_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mhistogram_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\udemy_tensorflow\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, log_dir, histogram_freq, write_graph, write_images, write_steps_per_second, update_freq, profile_batch, embeddings_freq, embeddings_metadata, **kwargs)\u001b[0m\n\u001b[0;32m   2174\u001b[0m     \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTensorBoard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2175\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_supports_tf_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2176\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2178\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpath_to_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\udemy_tensorflow\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_validate_kwargs\u001b[1;34m(self, kwargs)\u001b[0m\n\u001b[0;32m   2221\u001b[0m     \u001b[1;31m# Only allow kwargs that were supported in V1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0munrecognized_kwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2223\u001b[1;33m       raise ValueError(\n\u001b[0m\u001b[0;32m   2224\u001b[0m           \u001b[1;34m'Unrecognized arguments in `TensorBoard` Callback: '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2225\u001b[0m           f'{unrecognized_kwargs}. Supported kwargs are: {supported_kwargs}')\n",
      "\u001b[1;31mValueError\u001b[0m: Unrecognized arguments in `TensorBoard` Callback: {'print_batch'}. Supported kwargs are: {'embeddings_data', 'embeddings_layer_names', 'write_grads', 'batch_size'}"
     ]
    }
   ],
   "source": [
    "for idx, comb in enumerate(grid):\n",
    "    print(f'Running combination: {idx}')\n",
    "\n",
    "    model = build_model(\n",
    "        data.img_shape,\n",
    "        data.num_classes,\n",
    "        **comb\n",
    "    )\n",
    "\n",
    "    model_log_dir = os.path.join(LOGS_DIR, f'modelGrid{idx}')\n",
    "    if os.path.exists(model_log_dir):\n",
    "        shutil.rmtree(model_log_dir)\n",
    "        os.mkdir(model_log_dir)\n",
    "\n",
    "    tb_callback = TensorBoard(\n",
    "        log_dir=model_log_dir,\n",
    "        histogram_freq=0,\n",
    "        profile_batch=0\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        train_dataset,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        verbose=1,\n",
    "        validation_data=val_dataset,\n",
    "        callbacks=[tb_callback]\n",
    "    )\n",
    "\n",
    "    val_accuracy = model.evaluate(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        verbose=0\n",
    "    )[1]\n",
    "    results['val_scores'].append(val_accuracy)\n",
    "    results['params'].append(comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run_idx = np.argmax(results['val_scores'])\n",
    "results['best_score'] = results['val_scores'][best_run_idx]\n",
    "results['best_params'] = results['params'][best_run_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best score: {results['best_score']} using params: {results['best_params']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = results['val_scores']\n",
    "params = results['params']\n",
    "\n",
    "for score, param in zip(scores, params):\n",
    "    print(f'Score: {score} with param: {param}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "683035455952fa0c5c07396da2eac07ae1d76897e4164c7dcbe8556e60afc848"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('udemy_tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
