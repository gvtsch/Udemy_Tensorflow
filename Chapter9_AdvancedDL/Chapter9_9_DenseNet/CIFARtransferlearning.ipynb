{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "from tensorflow.keras.layers import Activation, Dense, GlobalAveragePooling2D, Input\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling, Resizing\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tf_utils.callbacks import schedule_fn2\n",
    "from tf_utils.Cifar10DataAdvanced import CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGENET_SIZE = 96\n",
    "IMAGENET_DEPTH = 3\n",
    "IMAGENET_SHAPE = (IMAGENET_SIZE, IMAGENET_SIZE, IMAGENET_DEPTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(img_shape, num_classes) -> Model:\n",
    "    base_model = MobileNetV2(\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "        input_shape=IMAGENET_SHAPE\n",
    "    )\n",
    "\n",
    "    num_layers = len(base_model.layers)\n",
    "    print(f\"Number of layers in the base model: {num_layers}\")\n",
    "    fine_tune_at = num_layers - 10\n",
    "    for layer in base_model.layers[:fine_tune_at]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    input_img = Input(shape=img_shape)\n",
    "    x = Rescaling(scale=2.0, offset=-1.0)(input_img)\n",
    "    x = Resizing(height=IMAGENET_SIZE, width=IMAGENET_SIZE)(x)\n",
    "    x = base_model(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(units=num_classes)(x)\n",
    "    y_pred = Activation(\"softmax\")(x)\n",
    "\n",
    "    model = Model(\n",
    "        inputs=[input_img],\n",
    "        outputs=[y_pred]\n",
    "    )\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Best model from chapter 8:   0.7200 accuracy\n",
    "- Best model from chapter 9_3: 0.8361 accuracy\n",
    "- Best model from chapter 9_7: 0.8993 accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = CIFAR10()\n",
    "\n",
    "train_dataset = data.get_train_set()\n",
    "val_dataset = data.get_val_set()\n",
    "test_dataset = data.get_test_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = data.img_shape\n",
    "num_classes = data.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers in the base model: 154\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " rescaling_7 (Rescaling)     (None, 32, 32, 3)         0         \n",
      "                                                                 \n",
      " resizing_1 (Resizing)       (None, 96, 96, 3)         0         \n",
      "                                                                 \n",
      " mobilenetv2_1.00_96 (Functi  (None, 3, 3, 1280)       2257984   \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " global_average_pooling2d_1   (None, 1280)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                12810     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,270,794\n",
      "Trainable params: 745,290\n",
      "Non-trainable params: 1,525,504\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(\n",
    "    img_shape,\n",
    "    num_classes\n",
    ")\n",
    "\n",
    "opt = Adam(learning_rate=5e-4)\n",
    "\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=opt,\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "lrs_callback = LearningRateScheduler(\n",
    "    schedule=schedule_fn2,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "es_callback = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=30,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 1/100\n",
      "262/262 [==============================] - 14s 44ms/step - loss: 0.4832 - accuracy: 0.8414 - val_loss: 1.1506 - val_accuracy: 0.8095 - lr: 0.0010\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 2/100\n",
      "262/262 [==============================] - 11s 43ms/step - loss: 0.2628 - accuracy: 0.9086 - val_loss: 1.0192 - val_accuracy: 0.8247 - lr: 0.0010\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 3/100\n",
      "262/262 [==============================] - 11s 43ms/step - loss: 0.1798 - accuracy: 0.9368 - val_loss: 0.9359 - val_accuracy: 0.8415 - lr: 0.0010\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 4/100\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.1209 - accuracy: 0.9590 - val_loss: 0.8723 - val_accuracy: 0.8517 - lr: 0.0010\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 5/100\n",
      "262/262 [==============================] - 11s 43ms/step - loss: 0.0862 - accuracy: 0.9714 - val_loss: 0.9319 - val_accuracy: 0.8515 - lr: 0.0010\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 6/100\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.0685 - accuracy: 0.9771 - val_loss: 0.9289 - val_accuracy: 0.8578 - lr: 0.0010\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 7/100\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.0631 - accuracy: 0.9788 - val_loss: 0.9997 - val_accuracy: 0.8555 - lr: 0.0010\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 8/100\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.0511 - accuracy: 0.9834 - val_loss: 0.8857 - val_accuracy: 0.8624 - lr: 0.0010\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 9/100\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.0513 - accuracy: 0.9823 - val_loss: 0.9263 - val_accuracy: 0.8625 - lr: 0.0010\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 10/100\n",
      "262/262 [==============================] - 11s 43ms/step - loss: 0.0442 - accuracy: 0.9858 - val_loss: 0.8699 - val_accuracy: 0.8727 - lr: 0.0010\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 11/100\n",
      "262/262 [==============================] - 12s 44ms/step - loss: 0.0330 - accuracy: 0.9887 - val_loss: 0.7801 - val_accuracy: 0.8723 - lr: 0.0010\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 0.0009048374180359595.\n",
      "Epoch 12/100\n",
      "262/262 [==============================] - 12s 46ms/step - loss: 0.0265 - accuracy: 0.9919 - val_loss: 0.7142 - val_accuracy: 0.8794 - lr: 9.0484e-04\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 0.0008187307530779819.\n",
      "Epoch 13/100\n",
      "262/262 [==============================] - 12s 46ms/step - loss: 0.0157 - accuracy: 0.9954 - val_loss: 0.7248 - val_accuracy: 0.8784 - lr: 8.1873e-04\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 0.0007408182206817179.\n",
      "Epoch 14/100\n",
      "262/262 [==============================] - 12s 46ms/step - loss: 0.0089 - accuracy: 0.9981 - val_loss: 0.6706 - val_accuracy: 0.8818 - lr: 7.4082e-04\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 0.0006703200460356394.\n",
      "Epoch 15/100\n",
      "262/262 [==============================] - 12s 46ms/step - loss: 0.0048 - accuracy: 0.9993 - val_loss: 0.6265 - val_accuracy: 0.8860 - lr: 6.7032e-04\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 0.0006065306597126335.\n",
      "Epoch 16/100\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.0026 - accuracy: 0.9997 - val_loss: 0.5863 - val_accuracy: 0.8872 - lr: 6.0653e-04\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 0.0005488116360940264.\n",
      "Epoch 17/100\n",
      "262/262 [==============================] - 11s 43ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.5729 - val_accuracy: 0.8888 - lr: 5.4881e-04\n",
      "\n",
      "Epoch 00018: LearningRateScheduler setting learning rate to 0.0004965853037914095.\n",
      "Epoch 18/100\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5656 - val_accuracy: 0.8912 - lr: 4.9659e-04\n",
      "\n",
      "Epoch 00019: LearningRateScheduler setting learning rate to 0.0004493289641172216.\n",
      "Epoch 19/100\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 9.0565e-04 - accuracy: 1.0000 - val_loss: 0.5531 - val_accuracy: 0.8916 - lr: 4.4933e-04\n",
      "\n",
      "Epoch 00020: LearningRateScheduler setting learning rate to 0.00040656965974059914.\n",
      "Epoch 20/100\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 6.4352e-04 - accuracy: 1.0000 - val_loss: 0.5480 - val_accuracy: 0.8928 - lr: 4.0657e-04\n",
      "\n",
      "Epoch 00021: LearningRateScheduler setting learning rate to 0.00036787944117144236.\n",
      "Epoch 21/100\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 5.9060e-04 - accuracy: 1.0000 - val_loss: 0.5479 - val_accuracy: 0.8910 - lr: 3.6788e-04\n",
      "\n",
      "Epoch 00022: LearningRateScheduler setting learning rate to 0.00033287108369807955.\n",
      "Epoch 22/100\n",
      "262/262 [==============================] - 11s 43ms/step - loss: 4.8060e-04 - accuracy: 1.0000 - val_loss: 0.5460 - val_accuracy: 0.8935 - lr: 3.3287e-04\n",
      "\n",
      "Epoch 00023: LearningRateScheduler setting learning rate to 0.00030119421191220205.\n",
      "Epoch 23/100\n",
      "262/262 [==============================] - 12s 45ms/step - loss: 4.7406e-04 - accuracy: 1.0000 - val_loss: 0.5525 - val_accuracy: 0.8924 - lr: 3.0119e-04\n",
      "\n",
      "Epoch 00024: LearningRateScheduler setting learning rate to 0.0002725317930340126.\n",
      "Epoch 24/100\n",
      "262/262 [==============================] - 12s 45ms/step - loss: 4.7481e-04 - accuracy: 1.0000 - val_loss: 0.5507 - val_accuracy: 0.8926 - lr: 2.7253e-04\n",
      "\n",
      "Epoch 00025: LearningRateScheduler setting learning rate to 0.00024659696394160646.\n",
      "Epoch 25/100\n",
      "262/262 [==============================] - 12s 46ms/step - loss: 4.3115e-04 - accuracy: 1.0000 - val_loss: 0.5515 - val_accuracy: 0.8934 - lr: 2.4660e-04\n",
      "\n",
      "Epoch 00026: LearningRateScheduler setting learning rate to 0.00022313016014842982.\n",
      "Epoch 26/100\n",
      "262/262 [==============================] - 12s 46ms/step - loss: 5.9729e-04 - accuracy: 0.9999 - val_loss: 0.5640 - val_accuracy: 0.8906 - lr: 2.2313e-04\n",
      "\n",
      "Epoch 00027: LearningRateScheduler setting learning rate to 0.00020189651799465538.\n",
      "Epoch 27/100\n",
      "262/262 [==============================] - 12s 47ms/step - loss: 5.9508e-04 - accuracy: 1.0000 - val_loss: 0.5643 - val_accuracy: 0.8920 - lr: 2.0190e-04\n",
      "\n",
      "Epoch 00028: LearningRateScheduler setting learning rate to 0.0001826835240527346.\n",
      "Epoch 28/100\n",
      "262/262 [==============================] - 12s 46ms/step - loss: 4.0770e-04 - accuracy: 1.0000 - val_loss: 0.5564 - val_accuracy: 0.8928 - lr: 1.8268e-04\n",
      "\n",
      "Epoch 00029: LearningRateScheduler setting learning rate to 0.00016529888822158653.\n",
      "Epoch 29/100\n",
      "262/262 [==============================] - 12s 45ms/step - loss: 3.1188e-04 - accuracy: 1.0000 - val_loss: 0.5579 - val_accuracy: 0.8924 - lr: 1.6530e-04\n",
      "\n",
      "Epoch 00030: LearningRateScheduler setting learning rate to 0.00014956861922263504.\n",
      "Epoch 30/100\n",
      "262/262 [==============================] - 12s 46ms/step - loss: 2.6013e-04 - accuracy: 1.0000 - val_loss: 0.5620 - val_accuracy: 0.8930 - lr: 1.4957e-04\n",
      "\n",
      "Epoch 00031: LearningRateScheduler setting learning rate to 0.0001353352832366127.\n",
      "Epoch 31/100\n",
      "262/262 [==============================] - 12s 45ms/step - loss: 2.6661e-04 - accuracy: 1.0000 - val_loss: 0.5639 - val_accuracy: 0.8933 - lr: 1.3534e-04\n",
      "\n",
      "Epoch 00032: LearningRateScheduler setting learning rate to 0.0001224564282529819.\n",
      "Epoch 32/100\n",
      "262/262 [==============================] - 12s 46ms/step - loss: 2.6832e-04 - accuracy: 1.0000 - val_loss: 0.5683 - val_accuracy: 0.8938 - lr: 1.2246e-04\n",
      "\n",
      "Epoch 00033: LearningRateScheduler setting learning rate to 0.00011080315836233387.\n",
      "Epoch 33/100\n",
      "262/262 [==============================] - 12s 45ms/step - loss: 2.2593e-04 - accuracy: 1.0000 - val_loss: 0.5691 - val_accuracy: 0.8935 - lr: 1.1080e-04\n",
      "\n",
      "Epoch 00034: LearningRateScheduler setting learning rate to 0.00010025884372280371.\n",
      "Epoch 34/100\n",
      "262/262 [==============================] - 12s 45ms/step - loss: 2.1900e-04 - accuracy: 1.0000 - val_loss: 0.5702 - val_accuracy: 0.8925 - lr: 1.0026e-04\n",
      "\n",
      "Epoch 00035: LearningRateScheduler setting learning rate to 9.071795328941248e-05.\n",
      "Epoch 35/100\n",
      "262/262 [==============================] - 12s 45ms/step - loss: 2.0388e-04 - accuracy: 1.0000 - val_loss: 0.5722 - val_accuracy: 0.8929 - lr: 9.0718e-05\n",
      "\n",
      "Epoch 00036: LearningRateScheduler setting learning rate to 8.20849986238988e-05.\n",
      "Epoch 36/100\n",
      "262/262 [==============================] - 12s 45ms/step - loss: 1.8978e-04 - accuracy: 1.0000 - val_loss: 0.5724 - val_accuracy: 0.8932 - lr: 8.2085e-05\n",
      "\n",
      "Epoch 00037: LearningRateScheduler setting learning rate to 7.427357821433387e-05.\n",
      "Epoch 37/100\n",
      "262/262 [==============================] - 12s 45ms/step - loss: 1.7572e-04 - accuracy: 1.0000 - val_loss: 0.5737 - val_accuracy: 0.8935 - lr: 7.4274e-05\n",
      "\n",
      "Epoch 00038: LearningRateScheduler setting learning rate to 6.720551273974975e-05.\n",
      "Epoch 38/100\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 1.7791e-04 - accuracy: 1.0000 - val_loss: 0.5771 - val_accuracy: 0.8932 - lr: 6.7206e-05\n",
      "\n",
      "Epoch 00039: LearningRateScheduler setting learning rate to 6.0810062625217954e-05.\n",
      "Epoch 39/100\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 1.5934e-04 - accuracy: 1.0000 - val_loss: 0.5784 - val_accuracy: 0.8934 - lr: 6.0810e-05\n",
      "\n",
      "Epoch 00040: LearningRateScheduler setting learning rate to 5.502322005640721e-05.\n",
      "Epoch 40/100\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 1.6238e-04 - accuracy: 1.0000 - val_loss: 0.5795 - val_accuracy: 0.8939 - lr: 5.5023e-05\n",
      "\n",
      "Epoch 00041: LearningRateScheduler setting learning rate to 4.9787068367863945e-05.\n",
      "Epoch 41/100\n",
      "262/262 [==============================] - 11s 43ms/step - loss: 1.9585e-04 - accuracy: 1.0000 - val_loss: 0.5815 - val_accuracy: 0.8933 - lr: 4.9787e-05\n",
      "\n",
      "Epoch 00042: LearningRateScheduler setting learning rate to 4.50492023935578e-05.\n",
      "Epoch 42/100\n",
      "262/262 [==============================] - 12s 45ms/step - loss: 1.5033e-04 - accuracy: 1.0000 - val_loss: 0.5805 - val_accuracy: 0.8934 - lr: 4.5049e-05\n",
      "\n",
      "Epoch 00043: LearningRateScheduler setting learning rate to 4.0762203978366214e-05.\n",
      "Epoch 43/100\n",
      "262/262 [==============================] - 12s 47ms/step - loss: 1.3361e-04 - accuracy: 1.0000 - val_loss: 0.5808 - val_accuracy: 0.8936 - lr: 4.0762e-05\n",
      "\n",
      "Epoch 00044: LearningRateScheduler setting learning rate to 3.688316740124e-05.\n",
      "Epoch 44/100\n",
      "262/262 [==============================] - 12s 46ms/step - loss: 1.4484e-04 - accuracy: 1.0000 - val_loss: 0.5820 - val_accuracy: 0.8940 - lr: 3.6883e-05\n",
      "\n",
      "Epoch 00045: LearningRateScheduler setting learning rate to 3.337326996032607e-05.\n",
      "Epoch 45/100\n",
      "262/262 [==============================] - 12s 46ms/step - loss: 1.3747e-04 - accuracy: 1.0000 - val_loss: 0.5850 - val_accuracy: 0.8929 - lr: 3.3373e-05\n",
      "\n",
      "Epoch 00046: LearningRateScheduler setting learning rate to 3.01973834223185e-05.\n",
      "Epoch 46/100\n",
      "262/262 [==============================] - 12s 46ms/step - loss: 1.3219e-04 - accuracy: 1.0000 - val_loss: 0.5863 - val_accuracy: 0.8933 - lr: 3.0197e-05\n",
      "\n",
      "Epoch 00047: LearningRateScheduler setting learning rate to 2.732372244729256e-05.\n",
      "Epoch 47/100\n",
      "262/262 [==============================] - 11s 43ms/step - loss: 1.2767e-04 - accuracy: 1.0000 - val_loss: 0.5883 - val_accuracy: 0.8938 - lr: 2.7324e-05\n",
      "\n",
      "Epoch 00048: LearningRateScheduler setting learning rate to 2.472352647033939e-05.\n",
      "Epoch 48/100\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 1.1046e-04 - accuracy: 1.0000 - val_loss: 0.5890 - val_accuracy: 0.8941 - lr: 2.4724e-05\n",
      "\n",
      "Epoch 00049: LearningRateScheduler setting learning rate to 2.2370771856165592e-05.\n",
      "Epoch 49/100\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 1.1403e-04 - accuracy: 1.0000 - val_loss: 0.5886 - val_accuracy: 0.8939 - lr: 2.2371e-05\n",
      "\n",
      "Epoch 00050: LearningRateScheduler setting learning rate to 2.024191144580438e-05.\n",
      "Epoch 50/100\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 1.0581e-04 - accuracy: 1.0000 - val_loss: 0.5906 - val_accuracy: 0.8947 - lr: 2.0242e-05\n",
      "\n",
      "Epoch 00051: LearningRateScheduler setting learning rate to 1.831563888873418e-05.\n",
      "Epoch 51/100\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 1.0283e-04 - accuracy: 1.0000 - val_loss: 0.5913 - val_accuracy: 0.8949 - lr: 1.8316e-05\n",
      "\n",
      "Epoch 00052: LearningRateScheduler setting learning rate to 1.657267540176124e-05.\n",
      "Epoch 52/100\n",
      "261/262 [============================>.] - ETA: 0s - loss: 1.0323e-04 - accuracy: 1.0000Restoring model weights from the end of the best epoch: 22.\n",
      "262/262 [==============================] - 11s 42ms/step - loss: 1.0317e-04 - accuracy: 1.0000 - val_loss: 0.5937 - val_accuracy: 0.8942 - lr: 1.6573e-05\n",
      "Epoch 00052: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x196b7ad8ee0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_dataset,\n",
    "    verbose=1,\n",
    "    epochs=epochs,\n",
    "    callbacks=[lrs_callback, es_callback],\n",
    "    validation_data=val_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.5460257530212402, 0.8934545516967773]\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(\n",
    "    val_dataset,\n",
    "    verbose=0\n",
    ")\n",
    "print(f\"Scores: {scores}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "683035455952fa0c5c07396da2eac07ae1d76897e4164c7dcbe8556e60afc848"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('udemy_tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
