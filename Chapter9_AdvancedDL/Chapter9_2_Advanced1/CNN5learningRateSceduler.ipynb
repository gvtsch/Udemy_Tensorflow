{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler # Adative Lernrate\n",
    "from tensorflow.keras.layers import ELU\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import MaxPool2D\n",
    "from tensorflow.keras.layers import ReLU\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam # Hat auch eine adaptive Lernrate\n",
    "\n",
    "from tf_utils.dogscatsDataAdvanced import DOGSCATS\n",
    "from tf_utils.callbacks import LRTensorBoard\n",
    "from tf_utils.callbacks import schedule_fn\n",
    "from tf_utils.callbacks import schedule_fn2\n",
    "from tf_utils.callbacks import schedule_fn3\n",
    "from tf_utils.callbacks import schedule_fn4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGS_DIR = os.path.abspath('C:/Selbststudium/Udemy/Udemy_Tensorflow/logs/DOGSCATS/')\n",
    "if not os.path.exists(LOGS_DIR):\n",
    "    os.mkdir(LOGS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(\n",
    "    img_shape: Tuple[int, int, int],\n",
    "    num_classes: int,\n",
    "    optimizer: tf.keras.optimizers.Optimizer,\n",
    "    learning_rate: float,\n",
    "    filter_block_1: int,\n",
    "    kernel_size_block_1: int,\n",
    "    filter_block_2: int,\n",
    "    kernel_size_block_2: int,\n",
    "    filter_block_3: int,\n",
    "    kernel_size_block_3: int,\n",
    "    dense_layer_size: int,\n",
    "    kernel_initializer: tf.keras.initializers.Initializer,\n",
    "    activation_cls: tf.keras.layers.Activation,\n",
    "    dropout_rate: float,\n",
    "    use_batch_normalization: bool\n",
    ") -> Model:\n",
    "    input_img = Input(shape=img_shape)\n",
    "\n",
    "    x = Conv2D(\n",
    "        filters=filter_block_1, \n",
    "        kernel_size=kernel_size_block_1, \n",
    "        padding='same', \n",
    "        kernel_initializer=kernel_initializer\n",
    "    )(input_img)\n",
    "    if use_batch_normalization:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = activation_cls(x)\n",
    "    x = Conv2D(\n",
    "        filters=filter_block_1, \n",
    "        kernel_size=kernel_size_block_1, \n",
    "        padding='same', \n",
    "        kernel_initializer=kernel_initializer\n",
    "    )(x)\n",
    "    if use_batch_normalization:\n",
    "        x = BatchNormalization()(x)\n",
    "    if dropout_rate:\n",
    "        x = Dropout(rate=dropout_rate)(x)\n",
    "    x = activation_cls(x)\n",
    "    x = MaxPool2D()(x)\n",
    "\n",
    "    x = Conv2D(\n",
    "        filters=filter_block_2, \n",
    "        kernel_size=kernel_size_block_2, \n",
    "        padding='same', \n",
    "        kernel_initializer=kernel_initializer\n",
    "    )(x)\n",
    "    if use_batch_normalization:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = activation_cls(x)\n",
    "    x = Conv2D(\n",
    "        filters=filter_block_2, \n",
    "        kernel_size=kernel_size_block_2, \n",
    "        padding='same', \n",
    "        kernel_initializer=kernel_initializer\n",
    "    )(x)\n",
    "    if use_batch_normalization:\n",
    "        x = BatchNormalization()(x)\n",
    "    if dropout_rate:\n",
    "        x = Dropout(rate=dropout_rate)(x)\n",
    "    x = activation_cls(x)\n",
    "    x = MaxPool2D()(x)\n",
    "\n",
    "    x = Conv2D(\n",
    "        filters=filter_block_3, \n",
    "        kernel_size=kernel_size_block_3, \n",
    "        padding='same', \n",
    "        kernel_initializer=kernel_initializer\n",
    "    )(x)\n",
    "    if use_batch_normalization:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = activation_cls(x)\n",
    "    x = Conv2D(\n",
    "        filters=filter_block_3, \n",
    "        kernel_size=kernel_size_block_3, \n",
    "        padding='same', \n",
    "        kernel_initializer=kernel_initializer\n",
    "    )(x)\n",
    "    if use_batch_normalization:\n",
    "        x = BatchNormalization()(x)\n",
    "    if dropout_rate:\n",
    "        x = Dropout(rate=dropout_rate)(x)\n",
    "    x = activation_cls(x)\n",
    "    x = MaxPool2D()(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(\n",
    "        units=dense_layer_size, \n",
    "        kernel_initializer=kernel_initializer\n",
    "    )(x)\n",
    "    if use_batch_normalization:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = activation_cls(x)\n",
    "    x = Dense(\n",
    "        units=num_classes, \n",
    "        kernel_initializer=kernel_initializer\n",
    "    )(x)\n",
    "    y_pred = Activation('softmax')(x)\n",
    "\n",
    "    # Jetzt muss noch ein Modell Objekt mit eben obiger Struktur erstellt werden\n",
    "    model = Model(\n",
    "        inputs = [input_img],\n",
    "        outputs = [y_pred]\n",
    "    )\n",
    "    \n",
    "    opt = optimizer(learning_rate=learning_rate)\n",
    "    \n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy', # wird bei Kategorie-Problemen mit mehr als 2 Klassen genommen\n",
    "        optimizer=opt,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DOGSCATS()\n",
    "\n",
    "train_dataset = data.get_train_set()\n",
    "val_dataset = data.get_val_set()\n",
    "test_dataset = data.get_test_set()\n",
    "\n",
    "img_shape = data.img_shape\n",
    "num_classes = data.num_classes\n",
    "\n",
    "epochs = 40\n",
    "batch_size = 128\n",
    "\n",
    "# Best model params\n",
    "params = {\n",
    "    \"optimizer\": Adam,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"filter_block_1\": 32,\n",
    "    \"kernel_size_block_1\": 3,\n",
    "    \"filter_block_2\": 64,\n",
    "    \"kernel_size_block_2\": 3,\n",
    "    \"filter_block_3\": 128,\n",
    "    \"kernel_size_block_3\": 3,\n",
    "    \"dense_layer_size\": 128,\n",
    "    \"kernel_initializer\": \"GlorotUniform\",\n",
    "    \"activation_cls\": ReLU(),\n",
    "    \"dropout_rate\": 0.0,\n",
    "    \"use_batch_normalization\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In diesem Video bzw. genau diesem Abschnitt wird Batch Normalization getestet\n",
    "\n",
    "model = build_model(\n",
    "    img_shape,\n",
    "    num_classes,\n",
    "    **params\n",
    ")\n",
    "\n",
    "schedules = [schedule_fn, schedule_fn2, schedule_fn3, schedule_fn4]\n",
    "\n",
    "for schedule in schedules:\n",
    "    model_log_dir = os.path.join(LOGS_DIR, f\"model{schedule.__name__}\")\n",
    "\n",
    "    tb_callback = TensorBoard(\n",
    "        log_dir=model_log_dir,\n",
    "        histogram_freq=0,\n",
    "        profile_batch=0,\n",
    "        write_graph=0\n",
    "    )\n",
    "\n",
    "    lrs_callback = LearningRateScheduler(\n",
    "        schedule=schedule,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    lr_callback = LRTensorBoard(\n",
    "        log_dir=model_log_dir,\n",
    "        histogram_freq=0,\n",
    "        profile_batch=0,\n",
    "        write_graph=0\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        train_dataset,\n",
    "        verbose=1,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        callbacks=[lrs_callback, lr_callback],\n",
    "        validation_data=val_dataset,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "683035455952fa0c5c07396da2eac07ae1d76897e4164c7dcbe8556e60afc848"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('udemy_tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
