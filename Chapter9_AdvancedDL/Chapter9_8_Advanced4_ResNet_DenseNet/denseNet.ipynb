{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.layers.pooling import AveragePooling2D\n",
    "\n",
    "from tf_utils.mnistData_advance import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGS_DIR = os.path.abspath(\"C:/Selbststudium/Udemy/Udemy_Tensorflow/logs\")\n",
    "if not os.path.exists(LOGS_DIR):\n",
    "    os.mkdir(LOGS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_norm(x: tf.Tensor) -> tf.Tensor:\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_block(\n",
    "    x: tf.Tensor,\n",
    "    filters: int,\n",
    "    downsample: bool = False,\n",
    "    bottleneck: bool = False,\n",
    ") -> tf.Tensor:\n",
    "    x1 = Conv2D(\n",
    "        filters=filters,\n",
    "        strides=1,\n",
    "        kernel_size=3,\n",
    "        padding=\"same\",\n",
    "    )(x)\n",
    "    x1 = relu_norm(x1)\n",
    "    x2 = Conv2D(\n",
    "        filters=filters,\n",
    "        strides=1,\n",
    "        kernel_size=3,\n",
    "        padding=\"same\",\n",
    "    )(x1)\n",
    "    x2 = relu_norm(x2)\n",
    "    out = Concatenate()([x1, x2])\n",
    "    if bottleneck:\n",
    "        out = Conv2D(\n",
    "            filters=filters,\n",
    "            strides=1,\n",
    "            kernel_size=1,\n",
    "            padding=\"same\"\n",
    "        )(out)\n",
    "    if downsample:\n",
    "        out = AveragePooling2D(pool_size=(2, 2))(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_block(x: tf.Tensor, num_classes: int) -> tf.Tensor:\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(\n",
    "        units=num_classes,\n",
    "    )(x)\n",
    "    x = Activation(\"softmax\")(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_densenet(\n",
    "    img_shape: Tuple[int, int, int],\n",
    "    num_classes: int,\n",
    ") -> Model:\n",
    "    input_img = Input(shape=img_shape)\n",
    "\n",
    "    x = dense_block(\n",
    "        x=input_img,\n",
    "        filters=32,\n",
    "        downsample=True,\n",
    "        bottleneck=True\n",
    "    )\n",
    "    x = dense_block(\n",
    "        x=x,\n",
    "        filters=64,\n",
    "        downsample=False,\n",
    "        bottleneck=True\n",
    "    )\n",
    "    x = dense_block(\n",
    "        x=x,\n",
    "        filters=64,\n",
    "        downsample=False,\n",
    "        bottleneck=True\n",
    "    )\n",
    "    x = dense_block(\n",
    "        x=x,\n",
    "        filters=128,\n",
    "        downsample=True,\n",
    "        bottleneck=True\n",
    "    )\n",
    "    x = dense_block(\n",
    "        x=x,\n",
    "        filters=128,\n",
    "        downsample=False,\n",
    "        bottleneck=True\n",
    "    )\n",
    "    y_pred = output_block(x=x, num_classes=num_classes)\n",
    "\n",
    "    model = Model(inputs=[input_img], outputs=[y_pred])\n",
    "\n",
    "    opt = Adam()\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = MNIST()\n",
    "\n",
    "train_dataset = data.get_train_set()\n",
    "val_dataset = data.get_val_set()\n",
    "test_dataset = data.get_test_set()\n",
    "\n",
    "img_shape = data.img_shape\n",
    "num_classes = data.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model_densenet(\n",
    "    img_shape,\n",
    "    num_classes,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_log_dir = os.path.join(LOGS_DIR, \"model_densenet_mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_callback = EarlyStopping(\n",
    "    monitor=\"val_accuracy\",\n",
    "    patience=30,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True,\n",
    "    min_delta=0.0005\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    verbose=1,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=[es_callback],\n",
    "    validation_data=val_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(\n",
    "    val_dataset,\n",
    "    verbose=0,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "print(f\"Scores: {scores}\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "683035455952fa0c5c07396da2eac07ae1d76897e4164c7dcbe8556e60afc848"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('udemy_tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
