{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGS_DIR = os.path.abspath(\"C:/Selbststudium/Udemy/Udemy_Tensorflow/logs/computation\")\n",
    "MODEL_LOG_DIR = os.path.join(LOGS_DIR, \"gradient_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset() -> Tuple[np.ndarray, np.ndarray]:\n",
    "    x = np.array(\n",
    "        [[i, i] for i in range(100)],\n",
    "        dtype=np.float32\n",
    "    )\n",
    "    y = np.array(\n",
    "        [i for i in range(100)],\n",
    "        dtype=np.float32\n",
    "    ).reshape(-1, 1)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model() -> Sequential:\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=1, input_shape=(2,), name=\"hidden\"))\n",
    "    model.add(Activation(\"relu\", name=\"relu\"))\n",
    "    model.add(Dense(units=1, name=\"output\"))\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gradients(\n",
    "    x_test: np.ndarray,\n",
    "    y_test: np.ndarray,\n",
    "    model: Sequential,\n",
    "    loss_object: tf.keras.losses.Loss\n",
    ") -> List[Tuple[np.ndarray, np.ndarray]]:\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(x_test, training=True)\n",
    "        loss_value = loss_object(y_test, y_pred)\n",
    "    grads = tape.gradient(loss_value, model.trainable_variables)\n",
    "    grad_var_tuples = [\n",
    "        (g, w) for (g, w) in zip(grads, model.trainable_variables)\n",
    "    ]\n",
    "    return grad_var_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = get_dataset()\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "model.compile(\n",
    "    loss=\"mse\",\n",
    "    optimizer=Adam(learning_rate=1e-2),\n",
    "    metrics=[\"mse\"]\n",
    ")\n",
    "\n",
    "tb_callback = TensorBoard(\n",
    "    log_dir=MODEL_LOG_DIR,\n",
    "    embeddings_freq=0,\n",
    "    write_graph=True\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    x=x,\n",
    "    y=y,\n",
    "    verbose=1,\n",
    "    batch_size=1,\n",
    "    epochs=0,\n",
    "    callbacks=[tb_callback]\n",
    ")\n",
    "\n",
    "model.layers[0].set_weights(\n",
    "    [np.array([[-0.250], [1.000]]),\n",
    "        np.array([0.100])]\n",
    ")\n",
    "model.layers[2].set_weights(\n",
    "    [np.array([[1.250]]),\n",
    "        np.array([0.125])]\n",
    ")\n",
    "\n",
    "# Test\n",
    "loss_object = MeanSquaredError()\n",
    "\n",
    "x_test = np.array([[2, 2]])\n",
    "y_test = np.array([[2]])\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "print(f\"Pred: {y_pred}\")\n",
    "\n",
    "gradients = get_gradients(x_test, y_test, model, loss_object)\n",
    "\n",
    "for grads, weight in gradients:\n",
    "    print(f\"Weights:\\n{weight.numpy()}\")\n",
    "    print(f\"Grads:\\n{grads.numpy()}\\n\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
