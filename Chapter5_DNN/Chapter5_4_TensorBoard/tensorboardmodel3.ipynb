{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # Arbeiten mit Pfaden\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.initializers import Constant\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_DIR = os.path.abspath('C:/Selbststudium/Udemy/Udemy_Tensorflow/models')\n",
    "if not os.path.exists(MODELS_DIR):\n",
    "    os.mkdir(MODELS_DIR)\n",
    "MODEL_FILE_PATH = os.path.join(MODELS_DIR, 'mnist_model.h5')\n",
    "\n",
    "LOGS_DIR = os.path.abspath('C:/Selbststudium/Udemy/Udemy_Tensorflow/logs')\n",
    "if not os.path.exists(LOGS_DIR):\n",
    "    os.mkdir(LOGS_DIR)\n",
    "MODEL_LOG_DIR = os.path.join(LOGS_DIR, 'mnist_model3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(num_features: int, num_classes: int) -> Tuple[Tuple[np.ndarray, np.ndarray], Tuple[np.ndarray, np.ndarray]]:\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    \n",
    "    x_train = x_train.reshape(-1, num_features).astype(np.float32)\n",
    "    x_test  = x_test.reshape(-1, num_features).astype(np.float32)\n",
    "    \n",
    "    y_train = to_categorical(y_train, num_classes=num_classes, dtype=np.float32)\n",
    "    y_test  = to_categorical(y_test, num_classes=num_classes, dtype=np.float32)\n",
    "\n",
    "    print(f'x train shape: {x_train.shape}')\n",
    "    print(f'y train shape: {y_train.shape}')\n",
    "    print(f'x test shape: {x_test.shape}')\n",
    "    print(f'y test shape: {y_test.shape}')\n",
    "\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(num_features: int, num_classes: int) -> Sequential:\n",
    "    init_w = TruncatedNormal(mean=0.0, stddev=0.01)\n",
    "    init_b = Constant(value=0.0)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=500, kernel_initializer=init_w, bias_initializer=init_b, input_shape=(num_features,))) \n",
    "        # Kernel waere die W-, bias die b-Matrix (Weights und Bias)\n",
    "        # Müssen nicht angegeben werden, weil per Default praktische Zufallswerte gewählt werden\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(units=250, kernel_initializer=init_w, bias_initializer=init_b)) # Hier kein input_shape mehr angeben! Nur beim ersten Layer \n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(units=100, kernel_initializer=init_w, bias_initializer=init_b)) \n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(units=50, kernel_initializer=init_w, bias_initializer=init_b)) \n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(units=num_classes, kernel_initializer=init_w, bias_initializer=init_b))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main() -> None:\n",
    "    num_features = 784 # Bild hat 28*28 Pixel\n",
    "    num_classes = 10 # 10 Ziffern möglich\n",
    "    \n",
    "    (x_train, y_train), (x_test, y_test) = get_dataset(num_features, num_classes)\n",
    "    \n",
    "    model = build_model(num_features, num_classes)\n",
    "\n",
    "    opt = Adam(learning_rate=0.001)\n",
    "\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy', # wird bei Kategorie-Problemen mit mehr als 2 Klassen genommen\n",
    "        optimizer=opt,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    tb_callback = TensorBoard(\n",
    "        log_dir=MODEL_LOG_DIR,\n",
    "        histogram_freq=1,\n",
    "        write_graph=True\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        x=x_train,\n",
    "        y=y_train,\n",
    "        epochs=20,\n",
    "        batch_size=256,\n",
    "        verbose=1,\n",
    "        validation_data=(x_test, y_test),\n",
    "        callbacks=[tb_callback]\n",
    "    )\n",
    "\n",
    "    scores = model.evaluate(\n",
    "        x=x_test, \n",
    "        y=y_test, \n",
    "        verbose=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x train shape: (60000, 784)\n",
      "y train shape: (60000, 10)\n",
      "x test shape: (10000, 784)\n",
      "y test shape: (10000, 10)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 500)               392500    \n",
      "                                                                 \n",
      " activation (Activation)     (None, 500)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 250)               125250    \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 250)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               25100     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 50)                5050      \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 50)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                510       \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 548,410\n",
      "Trainable params: 548,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.4528 - accuracy: 0.8533 - val_loss: 0.1462 - val_accuracy: 0.9576\n",
      "Epoch 2/20\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.1276 - accuracy: 0.9619 - val_loss: 0.1060 - val_accuracy: 0.9681\n",
      "Epoch 3/20\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0851 - accuracy: 0.9747 - val_loss: 0.0987 - val_accuracy: 0.9718\n",
      "Epoch 4/20\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0624 - accuracy: 0.9810 - val_loss: 0.0809 - val_accuracy: 0.9764\n",
      "Epoch 5/20\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0512 - accuracy: 0.9841 - val_loss: 0.1230 - val_accuracy: 0.9653\n",
      "Epoch 6/20\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0391 - accuracy: 0.9874 - val_loss: 0.0919 - val_accuracy: 0.9762\n",
      "Epoch 7/20\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0336 - accuracy: 0.9894 - val_loss: 0.0839 - val_accuracy: 0.9784\n",
      "Epoch 8/20\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0295 - accuracy: 0.9906 - val_loss: 0.0723 - val_accuracy: 0.9814\n",
      "Epoch 9/20\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0294 - accuracy: 0.9908 - val_loss: 0.0805 - val_accuracy: 0.9781\n",
      "Epoch 10/20\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0256 - accuracy: 0.9918 - val_loss: 0.0944 - val_accuracy: 0.9795\n",
      "Epoch 11/20\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0217 - accuracy: 0.9932 - val_loss: 0.0799 - val_accuracy: 0.9806\n",
      "Epoch 12/20\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0217 - accuracy: 0.9934 - val_loss: 0.0975 - val_accuracy: 0.9767\n",
      "Epoch 13/20\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0179 - accuracy: 0.9945 - val_loss: 0.0924 - val_accuracy: 0.9802\n",
      "Epoch 14/20\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0160 - accuracy: 0.9955 - val_loss: 0.0905 - val_accuracy: 0.9805\n",
      "Epoch 15/20\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0189 - accuracy: 0.9941 - val_loss: 0.0890 - val_accuracy: 0.9831\n",
      "Epoch 16/20\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0132 - accuracy: 0.9961 - val_loss: 0.0878 - val_accuracy: 0.9824\n",
      "Epoch 17/20\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0176 - accuracy: 0.9947 - val_loss: 0.0828 - val_accuracy: 0.9826\n",
      "Epoch 18/20\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0138 - accuracy: 0.9955 - val_loss: 0.0977 - val_accuracy: 0.9795\n",
      "Epoch 19/20\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0131 - accuracy: 0.9962 - val_loss: 0.1001 - val_accuracy: 0.9804\n",
      "Epoch 20/20\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0137 - accuracy: 0.9963 - val_loss: 0.1122 - val_accuracy: 0.9787\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "683035455952fa0c5c07396da2eac07ae1d76897e4164c7dcbe8556e60afc848"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('udemy_tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
