{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # Arbeiten mit Pfaden\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.initializers import Constant\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_DIR = os.path.abspath('C:/Selbststudium/Udemy/Udemy_Tensorflow/models')\n",
    "if not os.path.exists(MODELS_DIR):\n",
    "    os.mkdir(MODELS_DIR)\n",
    "MODEL_FILE_PATH = os.path.join(MODELS_DIR, 'mnist_model.h5')\n",
    "\n",
    "LOGS_DIR = os.path.abspath('C:/Selbststudium/Udemy/Udemy_Tensorflow/logs')\n",
    "if not os.path.exists(LOGS_DIR):\n",
    "    os.mkdir(LOGS_DIR)\n",
    "MODEL_LOG_DIR = os.path.join(LOGS_DIR, 'mnist_model3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(num_features: int, num_classes: int) -> Tuple[Tuple[np.ndarray, np.ndarray], Tuple[np.ndarray, np.ndarray]]:\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    \n",
    "    x_train = x_train.reshape(-1, num_features).astype(np.float32)\n",
    "    x_test  = x_test.reshape(-1, num_features).astype(np.float32)\n",
    "    \n",
    "    y_train = to_categorical(y_train, num_classes=num_classes, dtype=np.float32)\n",
    "    y_test  = to_categorical(y_test, num_classes=num_classes, dtype=np.float32)\n",
    "\n",
    "    print(f'x train shape: {x_train.shape}')\n",
    "    print(f'y train shape: {y_train.shape}')\n",
    "    print(f'x test shape: {x_test.shape}')\n",
    "    print(f'y test shape: {y_test.shape}')\n",
    "\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(num_features: int, num_classes: int) -> Sequential:\n",
    "    init_w = TruncatedNormal(mean=0.0, stddev=0.01)\n",
    "    init_b = Constant(value=0.0)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=500, kernel_initializer=init_w, bias_initializer=init_b, input_shape=(num_features,))) \n",
    "        # Kernel waere die W-, bias die b-Matrix (Weights und Bias)\n",
    "        # Müssen nicht angegeben werden, weil per Default praktische Zufallswerte gewählt werden\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(units=250, kernel_initializer=init_w, bias_initializer=init_b)) # Hier kein input_shape mehr angeben! Nur beim ersten Layer \n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(units=100, kernel_initializer=init_w, bias_initializer=init_b)) \n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(units=50, kernel_initializer=init_w, bias_initializer=init_b)) \n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(units=num_classes, kernel_initializer=init_w, bias_initializer=init_b))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main() -> None:\n",
    "    num_features = 784 # Bild hat 28*28 Pixel\n",
    "    num_classes = 10 # 10 Ziffern möglich\n",
    "    \n",
    "    (x_train, y_train), (x_test, y_test) = get_dataset(num_features, num_classes)\n",
    "    \n",
    "    model = build_model(num_features, num_classes)\n",
    "\n",
    "    opt = Adam(learning_rate=0.001)\n",
    "\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy', # wird bei Kategorie-Problemen mit mehr als 2 Klassen genommen\n",
    "        optimizer=opt,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    tb_callback = TensorBoard(\n",
    "        log_dir=MODEL_LOG_DIR,\n",
    "        histogram_freq=1,\n",
    "        write_graph=True\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        x=x_train,\n",
    "        y=y_train,\n",
    "        epochs=20,\n",
    "        batch_size=256,\n",
    "        verbose=1,\n",
    "        validation_data=(x_test, y_test),\n",
    "        callbacks=[tb_callback]\n",
    "    )\n",
    "\n",
    "    scores = model.evaluate(\n",
    "        x=x_test, \n",
    "        y=y_test, \n",
    "        verbose=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x train shape: (60000, 784)\n",
      "y train shape: (60000, 10)\n",
      "x test shape: (10000, 784)\n",
      "y test shape: (10000, 10)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 500)               392500    \n",
      "                                                                 \n",
      " activation (Activation)     (None, 500)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 250)               125250    \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 250)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               25100     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 50)                5050      \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 50)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                510       \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 548,410\n",
      "Trainable params: 548,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "235/235 [==============================] - 11s 35ms/step - loss: 0.4576 - accuracy: 0.8532 - val_loss: 0.1529 - val_accuracy: 0.9544\n",
      "Epoch 2/20\n",
      "235/235 [==============================] - 5s 19ms/step - loss: 0.1305 - accuracy: 0.9611 - val_loss: 0.1111 - val_accuracy: 0.9679\n",
      "Epoch 3/20\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.0839 - accuracy: 0.9737 - val_loss: 0.1034 - val_accuracy: 0.9704\n",
      "Epoch 4/20\n",
      "235/235 [==============================] - 3s 14ms/step - loss: 0.0620 - accuracy: 0.9808 - val_loss: 0.0874 - val_accuracy: 0.9755\n",
      "Epoch 5/20\n",
      "235/235 [==============================] - 3s 14ms/step - loss: 0.0503 - accuracy: 0.9838 - val_loss: 0.0833 - val_accuracy: 0.9752\n",
      "Epoch 6/20\n",
      "235/235 [==============================] - 4s 16ms/step - loss: 0.0395 - accuracy: 0.9880 - val_loss: 0.0889 - val_accuracy: 0.9758\n",
      "Epoch 7/20\n",
      "235/235 [==============================] - 4s 16ms/step - loss: 0.0307 - accuracy: 0.9903 - val_loss: 0.1065 - val_accuracy: 0.9759\n",
      "Epoch 8/20\n",
      "235/235 [==============================] - 4s 18ms/step - loss: 0.0314 - accuracy: 0.9899 - val_loss: 0.0841 - val_accuracy: 0.9800\n",
      "Epoch 9/20\n",
      "235/235 [==============================] - 4s 16ms/step - loss: 0.0247 - accuracy: 0.9923 - val_loss: 0.0846 - val_accuracy: 0.9780\n",
      "Epoch 10/20\n",
      "235/235 [==============================] - 3s 14ms/step - loss: 0.0271 - accuracy: 0.9915 - val_loss: 0.1049 - val_accuracy: 0.9747\n",
      "Epoch 11/20\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.0206 - accuracy: 0.9934 - val_loss: 0.0954 - val_accuracy: 0.9767\n",
      "Epoch 12/20\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0218 - accuracy: 0.9932 - val_loss: 0.0838 - val_accuracy: 0.9798\n",
      "Epoch 13/20\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0165 - accuracy: 0.9947 - val_loss: 0.0954 - val_accuracy: 0.9793\n",
      "Epoch 14/20\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0187 - accuracy: 0.9940 - val_loss: 0.1185 - val_accuracy: 0.9749\n",
      "Epoch 15/20\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0164 - accuracy: 0.9947 - val_loss: 0.0973 - val_accuracy: 0.9810\n",
      "Epoch 16/20\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0182 - accuracy: 0.9945 - val_loss: 0.0966 - val_accuracy: 0.9779\n",
      "Epoch 17/20\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0146 - accuracy: 0.9958 - val_loss: 0.0930 - val_accuracy: 0.9787\n",
      "Epoch 18/20\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0131 - accuracy: 0.9960 - val_loss: 0.0926 - val_accuracy: 0.9793\n",
      "Epoch 19/20\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0127 - accuracy: 0.9963 - val_loss: 0.0989 - val_accuracy: 0.9805\n",
      "Epoch 20/20\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0115 - accuracy: 0.9968 - val_loss: 0.1037 - val_accuracy: 0.9810\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "683035455952fa0c5c07396da2eac07ae1d76897e4164c7dcbe8556e60afc848"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('udemy_tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
