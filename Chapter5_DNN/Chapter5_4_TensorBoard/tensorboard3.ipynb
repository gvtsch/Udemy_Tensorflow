{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # Arbeiten mit Pfaden\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.initializers import Constant\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tf_utils.callbacks import ConfusionMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_DIR = os.path.abspath('C:/Selbststudium/Udemy/Udemy_Tensorflow/models')\n",
    "if not os.path.exists(MODELS_DIR):\n",
    "    os.mkdir(MODELS_DIR)\n",
    "MODEL_FILE_PATH = os.path.join(MODELS_DIR, 'mnist_model.h5')\n",
    "\n",
    "LOGS_DIR = os.path.abspath('C:/Selbststudium/Udemy/Udemy_Tensorflow/logs')\n",
    "if not os.path.exists(LOGS_DIR):\n",
    "    os.mkdir(LOGS_DIR)\n",
    "MODEL_LOG_DIR = os.path.join(LOGS_DIR, 'mnist_cm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(num_features: int, num_classes: int) -> Tuple[Tuple[np.ndarray, np.ndarray], Tuple[np.ndarray, np.ndarray]]:\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    \n",
    "    x_train = x_train.reshape(-1, num_features).astype(np.float32)\n",
    "    x_test  = x_test.reshape(-1, num_features).astype(np.float32)\n",
    "    \n",
    "    y_train = to_categorical(y_train, num_classes=num_classes, dtype=np.float32)\n",
    "    y_test  = to_categorical(y_test, num_classes=num_classes, dtype=np.float32)\n",
    "\n",
    "    print(f'x train shape: {x_train.shape}')\n",
    "    print(f'y train shape: {y_train.shape}')\n",
    "    print(f'x test shape: {x_test.shape}')\n",
    "    print(f'y test shape: {y_test.shape}')\n",
    "\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(num_features: int, num_classes: int) -> Sequential:\n",
    "    init_w = TruncatedNormal(mean=0.0, stddev=0.01)\n",
    "    init_b = Constant(value=0.0)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=500, kernel_initializer=init_w, bias_initializer=init_b, input_shape=(num_features,))) \n",
    "        # Kernel waere die W-, bias die b-Matrix (Weights und Bias)\n",
    "        # Müssen nicht angegeben werden, weil per Default praktische Zufallswerte gewählt werden\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(units=250, kernel_initializer=init_w, bias_initializer=init_b)) # Hier kein input_shape mehr angeben! Nur beim ersten Layer \n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(units=100, kernel_initializer=init_w, bias_initializer=init_b)) \n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(units=50, kernel_initializer=init_w, bias_initializer=init_b)) \n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(units=num_classes, kernel_initializer=init_w, bias_initializer=init_b))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main() -> None:\n",
    "    num_features = 784 # Bild hat 28*28 Pixel\n",
    "    num_classes = 10 # 10 Ziffern möglich\n",
    "    \n",
    "    (x_train, y_train), (x_test, y_test) = get_dataset(num_features, num_classes)\n",
    "    \n",
    "    model = build_model(num_features, num_classes)\n",
    "\n",
    "    opt = Adam(learning_rate=0.001)\n",
    "\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy', # wird bei Kategorie-Problemen mit mehr als 2 Klassen genommen\n",
    "        optimizer=opt,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    tb_callback = TensorBoard(\n",
    "        log_dir=MODEL_LOG_DIR,\n",
    "        histogram_freq=1,\n",
    "        write_graph=True\n",
    "    )\n",
    "\n",
    "    classes_list = [class_idx for class_idx in range(num_classes)]\n",
    "\n",
    "    cm_callback = ConfusionMatrix(\n",
    "        model,\n",
    "        x_test,\n",
    "        y_test,\n",
    "        classes_list=classes_list,\n",
    "        log_dir=MODEL_LOG_DIR\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        x=x_train,\n",
    "        y=y_train,\n",
    "        epochs=20,\n",
    "        batch_size=256,\n",
    "        verbose=1,\n",
    "        validation_data=(x_test, y_test),\n",
    "        callbacks=[tb_callback, cm_callback]\n",
    "    )\n",
    "\n",
    "    scores = model.evaluate(\n",
    "        x=x_test, \n",
    "        y=y_test, \n",
    "        verbose=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x train shape: (60000, 784)\n",
      "y train shape: (60000, 10)\n",
      "x test shape: (10000, 784)\n",
      "y test shape: (10000, 10)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 500)               392500    \n",
      "                                                                 \n",
      " activation (Activation)     (None, 500)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 250)               125250    \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 250)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               25100     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 50)                5050      \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 50)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                510       \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 548,410\n",
      "Trainable params: 548,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.4296 - accuracy: 0.8627 - val_loss: 0.1764 - val_accuracy: 0.9445\n",
      "Epoch 2/20\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.1214 - accuracy: 0.9636 - val_loss: 0.1200 - val_accuracy: 0.9628\n",
      "Epoch 3/20\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0816 - accuracy: 0.9748 - val_loss: 0.1067 - val_accuracy: 0.9684\n",
      "Epoch 4/20\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0624 - accuracy: 0.9806 - val_loss: 0.0761 - val_accuracy: 0.9778\n",
      "Epoch 5/20\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0499 - accuracy: 0.9845 - val_loss: 0.0871 - val_accuracy: 0.9765\n",
      "Epoch 6/20\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0390 - accuracy: 0.9875 - val_loss: 0.0927 - val_accuracy: 0.9745\n",
      "Epoch 7/20\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0334 - accuracy: 0.9897 - val_loss: 0.0816 - val_accuracy: 0.9797\n",
      "Epoch 8/20\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0283 - accuracy: 0.9908 - val_loss: 0.0883 - val_accuracy: 0.9774\n",
      "Epoch 9/20\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0287 - accuracy: 0.9911 - val_loss: 0.0967 - val_accuracy: 0.9756\n",
      "Epoch 10/20\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0240 - accuracy: 0.9929 - val_loss: 0.0925 - val_accuracy: 0.9798\n",
      "Epoch 11/20\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0223 - accuracy: 0.9931 - val_loss: 0.0783 - val_accuracy: 0.9807\n",
      "Epoch 12/20\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0175 - accuracy: 0.9948 - val_loss: 0.0954 - val_accuracy: 0.9799\n",
      "Epoch 13/20\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0176 - accuracy: 0.9952 - val_loss: 0.0888 - val_accuracy: 0.9801\n",
      "Epoch 14/20\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0194 - accuracy: 0.9940 - val_loss: 0.1036 - val_accuracy: 0.9785\n",
      "Epoch 15/20\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0189 - accuracy: 0.9944 - val_loss: 0.0958 - val_accuracy: 0.9793\n",
      "Epoch 16/20\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0147 - accuracy: 0.9956 - val_loss: 0.0900 - val_accuracy: 0.9811\n",
      "Epoch 17/20\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0134 - accuracy: 0.9958 - val_loss: 0.1407 - val_accuracy: 0.9737\n",
      "Epoch 18/20\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0153 - accuracy: 0.9956 - val_loss: 0.0935 - val_accuracy: 0.9805\n",
      "Epoch 19/20\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0120 - accuracy: 0.9964 - val_loss: 0.1047 - val_accuracy: 0.9796\n",
      "Epoch 20/20\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0132 - accuracy: 0.9962 - val_loss: 0.1101 - val_accuracy: 0.9793\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "683035455952fa0c5c07396da2eac07ae1d76897e4164c7dcbe8556e60afc848"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('udemy_tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
