{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Callable\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Activation, Dense, Input, SimpleRNN, LSTM, GRU\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.layers.pooling import AveragePooling2D\n",
    "\n",
    "from tf_utils.imdbDataAdvanced import IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rnn_model(input_shape: Tuple[int, int], num_classes: int) -> Model:\n",
    "    input_text = Input(shape=input_shape)\n",
    "    x = SimpleRNN(units=80, return_sequences=False)(input_text) # False --> One to many --> Nicht in jedem Zeitschritt ein Output\n",
    "    x = Dense(units=80)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Dense(units=num_classes)(x)\n",
    "    out = Activation(\"softmax\")(x)\n",
    "    model = Model(inputs=[input_text], outputs=[out])\n",
    "    opt = Adam(learning_rate=1e-4)\n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"]\n",
    "    )\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm_model(input_shape: Tuple[int, int], num_classes: int) -> Model:\n",
    "    input_text = Input(shape=input_shape)\n",
    "    x = LSTM(units=80, return_sequences=False)(input_text)\n",
    "    x = Dense(units=80)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Dense(units=num_classes)(x)\n",
    "    out = Activation(\"softmax\")(x)\n",
    "    model = Model(inputs=[input_text], outputs=[out])\n",
    "    opt = Adam(learning_rate=1e-4)\n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"]\n",
    "    )\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gru_model(input_shape: Tuple[int, int], num_classes: int) -> Model:\n",
    "    input_text = Input(shape=input_shape)\n",
    "    x = GRU(units=80, return_sequences=False)(input_text)\n",
    "    x = Dense(units=80)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Dense(units=num_classes)(x)\n",
    "    out = Activation(\"softmax\")(x)\n",
    "    model = Model(inputs=[input_text], outputs=[out])\n",
    "    opt = Adam(learning_rate=1e-4)\n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"]\n",
    "    )\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RNN\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 80, 1)]           0         \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, 80)                6560      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 80)                6480      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 80)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 162       \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,202\n",
      "Trainable params: 13,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "131/131 [==============================] - 10s 67ms/step - loss: 0.6948 - accuracy: 0.5082 - val_loss: 0.6935 - val_accuracy: 0.5115\n",
      "Epoch 2/20\n",
      "131/131 [==============================] - 9s 65ms/step - loss: 0.6929 - accuracy: 0.5171 - val_loss: 0.6927 - val_accuracy: 0.5127\n",
      "Epoch 3/20\n",
      "131/131 [==============================] - 8s 64ms/step - loss: 0.6922 - accuracy: 0.5176 - val_loss: 0.6924 - val_accuracy: 0.5149\n",
      "Epoch 4/20\n",
      "131/131 [==============================] - 8s 63ms/step - loss: 0.6918 - accuracy: 0.5183 - val_loss: 0.6923 - val_accuracy: 0.5165\n",
      "Epoch 5/20\n",
      "131/131 [==============================] - 9s 67ms/step - loss: 0.6915 - accuracy: 0.5192 - val_loss: 0.6922 - val_accuracy: 0.5161\n",
      "Epoch 6/20\n",
      "131/131 [==============================] - 9s 67ms/step - loss: 0.6912 - accuracy: 0.5218 - val_loss: 0.6922 - val_accuracy: 0.5168\n",
      "Epoch 7/20\n",
      "131/131 [==============================] - 9s 66ms/step - loss: 0.6911 - accuracy: 0.5231 - val_loss: 0.6921 - val_accuracy: 0.5168\n",
      "Epoch 8/20\n",
      "131/131 [==============================] - 9s 65ms/step - loss: 0.6909 - accuracy: 0.5229 - val_loss: 0.6922 - val_accuracy: 0.5166\n",
      "Epoch 9/20\n",
      "131/131 [==============================] - 9s 66ms/step - loss: 0.6907 - accuracy: 0.5228 - val_loss: 0.6922 - val_accuracy: 0.5159\n",
      "Epoch 10/20\n",
      "131/131 [==============================] - 8s 64ms/step - loss: 0.6906 - accuracy: 0.5244 - val_loss: 0.6923 - val_accuracy: 0.5165\n",
      "Epoch 11/20\n",
      "131/131 [==============================] - 9s 67ms/step - loss: 0.6905 - accuracy: 0.5253 - val_loss: 0.6924 - val_accuracy: 0.5149\n",
      "Epoch 12/20\n",
      "131/131 [==============================] - 8s 62ms/step - loss: 0.6905 - accuracy: 0.5315 - val_loss: 0.6929 - val_accuracy: 0.5167\n",
      "Epoch 13/20\n",
      "131/131 [==============================] - 8s 62ms/step - loss: 0.6902 - accuracy: 0.5318 - val_loss: 0.6928 - val_accuracy: 0.5153\n",
      "Epoch 14/20\n",
      "131/131 [==============================] - 8s 63ms/step - loss: 0.6900 - accuracy: 0.5299 - val_loss: 0.6928 - val_accuracy: 0.5126\n",
      "Epoch 15/20\n",
      "131/131 [==============================] - 8s 63ms/step - loss: 0.6899 - accuracy: 0.5293 - val_loss: 0.6927 - val_accuracy: 0.5118\n",
      "Epoch 16/20\n",
      "131/131 [==============================] - 9s 65ms/step - loss: 0.6898 - accuracy: 0.5298 - val_loss: 0.6927 - val_accuracy: 0.5120\n",
      "Epoch 17/20\n",
      "131/131 [==============================] - 9s 65ms/step - loss: 0.6897 - accuracy: 0.5299 - val_loss: 0.6927 - val_accuracy: 0.5136\n",
      "Epoch 18/20\n",
      "131/131 [==============================] - 8s 65ms/step - loss: 0.6896 - accuracy: 0.5304 - val_loss: 0.6927 - val_accuracy: 0.5145\n",
      "Epoch 19/20\n",
      "131/131 [==============================] - 8s 64ms/step - loss: 0.6895 - accuracy: 0.5295 - val_loss: 0.6927 - val_accuracy: 0.5162\n",
      "Epoch 20/20\n",
      "131/131 [==============================] - 9s 65ms/step - loss: 0.6894 - accuracy: 0.5297 - val_loss: 0.6927 - val_accuracy: 0.5171\n",
      "Test performance: [0.6935099959373474, 0.5116000175476074]\n",
      "Model: LSTM\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 80, 1)]           0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 80)                26240     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 80)                6480      \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 80)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 162       \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,882\n",
      "Trainable params: 32,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "131/131 [==============================] - 5s 21ms/step - loss: 0.6944 - accuracy: 0.5195 - val_loss: 0.6914 - val_accuracy: 0.5278\n",
      "Epoch 2/20\n",
      "131/131 [==============================] - 2s 17ms/step - loss: 0.6901 - accuracy: 0.5318 - val_loss: 0.6902 - val_accuracy: 0.5390\n",
      "Epoch 3/20\n",
      "131/131 [==============================] - 2s 17ms/step - loss: 0.6892 - accuracy: 0.5367 - val_loss: 0.6895 - val_accuracy: 0.5450\n",
      "Epoch 4/20\n",
      "131/131 [==============================] - 2s 17ms/step - loss: 0.6886 - accuracy: 0.5397 - val_loss: 0.6890 - val_accuracy: 0.5439\n",
      "Epoch 5/20\n",
      "131/131 [==============================] - 2s 17ms/step - loss: 0.6881 - accuracy: 0.5399 - val_loss: 0.6886 - val_accuracy: 0.5478\n",
      "Epoch 6/20\n",
      "131/131 [==============================] - 2s 17ms/step - loss: 0.6877 - accuracy: 0.5426 - val_loss: 0.6881 - val_accuracy: 0.5508\n",
      "Epoch 7/20\n",
      "131/131 [==============================] - 2s 17ms/step - loss: 0.6872 - accuracy: 0.5459 - val_loss: 0.6877 - val_accuracy: 0.5542\n",
      "Epoch 8/20\n",
      "131/131 [==============================] - 2s 17ms/step - loss: 0.6867 - accuracy: 0.5472 - val_loss: 0.6872 - val_accuracy: 0.5522\n",
      "Epoch 9/20\n",
      "131/131 [==============================] - 2s 17ms/step - loss: 0.6862 - accuracy: 0.5493 - val_loss: 0.6869 - val_accuracy: 0.5541\n",
      "Epoch 10/20\n",
      "131/131 [==============================] - 2s 17ms/step - loss: 0.6858 - accuracy: 0.5497 - val_loss: 0.6867 - val_accuracy: 0.5537\n",
      "Epoch 11/20\n",
      "131/131 [==============================] - 2s 17ms/step - loss: 0.6855 - accuracy: 0.5506 - val_loss: 0.6865 - val_accuracy: 0.5514\n",
      "Epoch 12/20\n",
      "131/131 [==============================] - 2s 17ms/step - loss: 0.6852 - accuracy: 0.5535 - val_loss: 0.6864 - val_accuracy: 0.5521\n",
      "Epoch 13/20\n",
      "131/131 [==============================] - 2s 17ms/step - loss: 0.6849 - accuracy: 0.5546 - val_loss: 0.6863 - val_accuracy: 0.5518\n",
      "Epoch 14/20\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.6847 - accuracy: 0.5548 - val_loss: 0.6862 - val_accuracy: 0.5525\n",
      "Epoch 15/20\n",
      "131/131 [==============================] - 2s 17ms/step - loss: 0.6845 - accuracy: 0.5555 - val_loss: 0.6861 - val_accuracy: 0.5525\n",
      "Epoch 16/20\n",
      "131/131 [==============================] - 2s 17ms/step - loss: 0.6843 - accuracy: 0.5557 - val_loss: 0.6860 - val_accuracy: 0.5504\n",
      "Epoch 17/20\n",
      "131/131 [==============================] - 2s 17ms/step - loss: 0.6842 - accuracy: 0.5561 - val_loss: 0.6860 - val_accuracy: 0.5515\n",
      "Epoch 18/20\n",
      "131/131 [==============================] - 2s 17ms/step - loss: 0.6840 - accuracy: 0.5565 - val_loss: 0.6859 - val_accuracy: 0.5521\n",
      "Epoch 19/20\n",
      "131/131 [==============================] - 2s 17ms/step - loss: 0.6839 - accuracy: 0.5570 - val_loss: 0.6859 - val_accuracy: 0.5524\n",
      "Epoch 20/20\n",
      "131/131 [==============================] - 2s 17ms/step - loss: 0.6837 - accuracy: 0.5571 - val_loss: 0.6859 - val_accuracy: 0.5536\n",
      "Test performance: [0.6868535280227661, 0.5484799742698669]\n",
      "Model: GRU\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 80, 1)]           0         \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 80)                19920     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 80)                6480      \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 80)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 162       \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26,562\n",
      "Trainable params: 26,562\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "131/131 [==============================] - 4s 18ms/step - loss: 0.6933 - accuracy: 0.5192 - val_loss: 0.6910 - val_accuracy: 0.5284\n",
      "Epoch 2/20\n",
      "131/131 [==============================] - 2s 16ms/step - loss: 0.6912 - accuracy: 0.5278 - val_loss: 0.6904 - val_accuracy: 0.5365\n",
      "Epoch 3/20\n",
      "131/131 [==============================] - 2s 16ms/step - loss: 0.6904 - accuracy: 0.5306 - val_loss: 0.6900 - val_accuracy: 0.5371\n",
      "Epoch 4/20\n",
      "131/131 [==============================] - 2s 16ms/step - loss: 0.6899 - accuracy: 0.5320 - val_loss: 0.6898 - val_accuracy: 0.5366\n",
      "Epoch 5/20\n",
      "131/131 [==============================] - 2s 16ms/step - loss: 0.6895 - accuracy: 0.5347 - val_loss: 0.6896 - val_accuracy: 0.5366\n",
      "Epoch 6/20\n",
      "131/131 [==============================] - 2s 15ms/step - loss: 0.6892 - accuracy: 0.5361 - val_loss: 0.6894 - val_accuracy: 0.5366\n",
      "Epoch 7/20\n",
      "131/131 [==============================] - 2s 16ms/step - loss: 0.6888 - accuracy: 0.5385 - val_loss: 0.6894 - val_accuracy: 0.5376\n",
      "Epoch 8/20\n",
      "131/131 [==============================] - 2s 15ms/step - loss: 0.6885 - accuracy: 0.5412 - val_loss: 0.6892 - val_accuracy: 0.5368\n",
      "Epoch 9/20\n",
      "131/131 [==============================] - 2s 16ms/step - loss: 0.6882 - accuracy: 0.5424 - val_loss: 0.6892 - val_accuracy: 0.5375\n",
      "Epoch 10/20\n",
      "131/131 [==============================] - 2s 16ms/step - loss: 0.6880 - accuracy: 0.5427 - val_loss: 0.6890 - val_accuracy: 0.5396\n",
      "Epoch 11/20\n",
      "131/131 [==============================] - 2s 16ms/step - loss: 0.6877 - accuracy: 0.5429 - val_loss: 0.6889 - val_accuracy: 0.5383\n",
      "Epoch 12/20\n",
      "131/131 [==============================] - 2s 17ms/step - loss: 0.6874 - accuracy: 0.5441 - val_loss: 0.6889 - val_accuracy: 0.5390\n",
      "Epoch 13/20\n",
      "131/131 [==============================] - 2s 16ms/step - loss: 0.6872 - accuracy: 0.5453 - val_loss: 0.6888 - val_accuracy: 0.5398\n",
      "Epoch 14/20\n",
      "131/131 [==============================] - 2s 17ms/step - loss: 0.6869 - accuracy: 0.5453 - val_loss: 0.6887 - val_accuracy: 0.5407\n",
      "Epoch 15/20\n",
      "131/131 [==============================] - 2s 16ms/step - loss: 0.6867 - accuracy: 0.5466 - val_loss: 0.6887 - val_accuracy: 0.5421\n",
      "Epoch 16/20\n",
      "131/131 [==============================] - 2s 16ms/step - loss: 0.6864 - accuracy: 0.5487 - val_loss: 0.6887 - val_accuracy: 0.5425\n",
      "Epoch 17/20\n",
      "131/131 [==============================] - 2s 16ms/step - loss: 0.6862 - accuracy: 0.5502 - val_loss: 0.6886 - val_accuracy: 0.5444\n",
      "Epoch 18/20\n",
      "131/131 [==============================] - 2s 16ms/step - loss: 0.6860 - accuracy: 0.5493 - val_loss: 0.6885 - val_accuracy: 0.5444\n",
      "Epoch 19/20\n",
      "131/131 [==============================] - 2s 16ms/step - loss: 0.6857 - accuracy: 0.5500 - val_loss: 0.6885 - val_accuracy: 0.5438\n",
      "Epoch 20/20\n",
      "131/131 [==============================] - 2s 15ms/step - loss: 0.6855 - accuracy: 0.5522 - val_loss: 0.6884 - val_accuracy: 0.5429\n",
      "Test performance: [0.6889957785606384, 0.5374000072479248]\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 20_000\n",
    "sequence_length = 80\n",
    "imdb_data = IMDB(vocab_size, sequence_length)\n",
    "train_dataset = imdb_data.get_train_set()\n",
    "val_dataset = imdb_data.get_val_set()\n",
    "test_dataset = imdb_data.get_test_set()\n",
    "input_shape = (sequence_length, 1)\n",
    "num_classes = imdb_data.num_classes\n",
    "\n",
    "batch_size = 512\n",
    "epochs = 10\n",
    "\n",
    "model_fns = {\n",
    "    \"RNN\": create_rnn_model,\n",
    "    \"LSTM\": create_lstm_model,\n",
    "    \"GRU\": create_gru_model,\n",
    "}\n",
    "\n",
    "for name, model_fn in model_fns.items():\n",
    "    print(f\"Model: {name}\")\n",
    "    model = model_fn(input_shape, num_classes)\n",
    "    model.fit(\n",
    "        x=train_dataset,\n",
    "        verbose=1,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=val_dataset,\n",
    "    )\n",
    "    score = model.evaluate(x=test_dataset, verbose=0, batch_size=batch_size)\n",
    "    print(f\"Test performance: {score}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "683035455952fa0c5c07396da2eac07ae1d76897e4164c7dcbe8556e60afc848"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('udemy_tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
