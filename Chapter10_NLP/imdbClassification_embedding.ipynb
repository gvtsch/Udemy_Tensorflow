{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Callable\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Activation, Dense, Input, SimpleRNN, LSTM, GRU, Embedding\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.layers.pooling import AveragePooling2D\n",
    "\n",
    "from tf_utils.imdbDataAdvanced import IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rnn_model(\n",
    "    input_shape: Tuple[int, int], \n",
    "    num_classes: int, \n",
    "    vocab_size: int, \n",
    "    embedding_dim: int, \n",
    "    sequence_length: int\n",
    ") -> Model:\n",
    "    input_text = Input(shape=input_shape)\n",
    "    x = Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=embedding_dim,\n",
    "        input_length=sequence_length\n",
    "    )(input_text)\n",
    "    x = SimpleRNN(units=80)(x) # False --> One to many --> Nicht in jedem Zeitschritt ein Output\n",
    "    x = Dense(units=80)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Dense(units=num_classes)(x)\n",
    "    out = Activation(\"softmax\")(x)\n",
    "    model = Model(inputs=[input_text], outputs=[out])\n",
    "    opt = Adam(learning_rate=1e-4)\n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"]\n",
    "    )\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm_model(\n",
    "    input_shape: Tuple[int, int], \n",
    "    num_classes: int, \n",
    "    vocab_size: int, \n",
    "    embedding_dim: int, \n",
    "    sequence_length: int\n",
    ") -> Model:\n",
    "    input_text = Input(shape=input_shape)\n",
    "    x = Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=embedding_dim,\n",
    "        input_length=sequence_length\n",
    "    )(input_text)\n",
    "    x = LSTM(units=80)(x)\n",
    "    x = Dense(units=80)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Dense(units=num_classes)(x)\n",
    "    out = Activation(\"softmax\")(x)\n",
    "    model = Model(inputs=[input_text], outputs=[out])\n",
    "    opt = Adam(learning_rate=1e-4)\n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"]\n",
    "    )\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gru_model(\n",
    "    input_shape: Tuple[int, int], \n",
    "    num_classes: int, \n",
    "    vocab_size: int, \n",
    "    embedding_dim: int, \n",
    "    sequence_length: int\n",
    ") -> Model:\n",
    "    input_text = Input(shape=input_shape)\n",
    "    x = Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=embedding_dim,\n",
    "        input_length=sequence_length\n",
    "    )(input_text)\n",
    "    x = GRU(units=80)(x)\n",
    "    x = Dense(units=80)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Dense(units=num_classes)(x)\n",
    "    out = Activation(\"softmax\")(x)\n",
    "    model = Model(inputs=[input_text], outputs=[out])\n",
    "    opt = Adam(learning_rate=1e-4)\n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"]\n",
    "    )\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RNN\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 80)]              0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 80, 50)            1000000   \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, 80)                10480     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 80)                6480      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 80)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 162       \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,017,122\n",
      "Trainable params: 1,017,122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test performance: [0.6955727934837341, 0.4975599944591522]\n",
      "Model: LSTM\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 80)]              0         \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, 80, 50)            1000000   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 80)                41920     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 80)                6480      \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 80)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 162       \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,048,562\n",
      "Trainable params: 1,048,562\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test performance: [0.6931123733520508, 0.5055199861526489]\n",
      "Model: GRU\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 80)]              0         \n",
      "                                                                 \n",
      " embedding_2 (Embedding)     (None, 80, 50)            1000000   \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 80)                31680     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 80)                6480      \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 80)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 162       \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,038,322\n",
      "Trainable params: 1,038,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test performance: [0.6930521726608276, 0.5034400224685669]\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 20_000\n",
    "sequence_length = 80\n",
    "embedding_dim = 50\n",
    "imdb_data = IMDB(vocab_size, sequence_length)\n",
    "train_dataset = imdb_data.get_train_set()\n",
    "val_dataset = imdb_data.get_val_set()\n",
    "test_dataset = imdb_data.get_test_set()\n",
    "input_shape = (sequence_length, )\n",
    "num_classes = imdb_data.num_classes\n",
    "\n",
    "batch_size = 512\n",
    "epochs = 0\n",
    "\n",
    "model_fns = {\n",
    "    \"RNN\": create_rnn_model,\n",
    "    \"LSTM\": create_lstm_model,\n",
    "    \"GRU\": create_gru_model,\n",
    "}\n",
    "\n",
    "for name, model_fn in model_fns.items():\n",
    "    print(f\"Model: {name}\")\n",
    "    model = model_fn(input_shape, num_classes, vocab_size, embedding_dim, sequence_length)\n",
    "    model.fit(x=train_dataset, verbose=1, batch_size=batch_size, epochs=epochs, validation_data=val_dataset)\n",
    "    score = model.evaluate(x=test_dataset, verbose=0, batch_size=batch_size)\n",
    "    print(f\"Test performance: {score}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "683035455952fa0c5c07396da2eac07ae1d76897e4164c7dcbe8556e60afc848"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('udemy_tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
