{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2D(image: np.ndarray, kernel: np.ndarray) -> np.ndarray:\n",
    "    rows, cols = image.shape\n",
    "\n",
    "    conv_image = np.zeros(shape=(rows, cols), dtype=np.float32)\n",
    "    padded_image = np.zeros(shape=(rows + 2, cols + 2))\n",
    "    padded_image[1:-1, 1:-1] = image\n",
    "\n",
    "    padded_rows, padded_cols = padded_image.shape\n",
    "\n",
    "    for i_out, i in enumerate(range(1, padded_rows - 1)):\n",
    "        for j_out, j in enumerate(range(1, padded_cols - 1)):\n",
    "            image_slice = padded_image[i-1: i+2, j-1: j+2]\n",
    "            conv_image[i_out, j_out] = np.sum(kernel * image_slice)\n",
    "\n",
    "    return conv_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prvious shape: (4, 4) current shape: (4, 4)\n",
      "Conved Image:\n",
      "[[10. 18. 24. 18.]\n",
      " [27. 45. 54. 39.]\n",
      " [51. 81. 90. 63.]\n",
      " [42. 66. 72. 50.]]\n",
      "Conved Image TF:\n",
      "[[10. 18. 24. 18.]\n",
      " [27. 45. 54. 39.]\n",
      " [51. 81. 90. 63.]\n",
      " [42. 66. 72. 50.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "image = np.arange(16)\n",
    "image = image.reshape((4, 4)).astype(np.float32)\n",
    "kernel = np.ones(shape=(3, 3))\n",
    "\n",
    "conv_image = conv2D(image, kernel)\n",
    "\n",
    "print(f\"Prvious shape: {image.shape} current shape: {conv_image.shape}\")\n",
    "print(f\"Conved Image:\\n{conv_image.squeeze()}\")\n",
    "\n",
    "layer = Conv2D(filters=1, kernel_size=(3, 3), strides=1, padding='same')\n",
    "layer.build((4, 4, 1))\n",
    "W, b = layer.get_weights()\n",
    "layer.set_weights([np.ones_like(W), np.zeros_like(b)])\n",
    "conv_image_tf = layer(image.reshape((1, 4, 4, 1))).numpy()\n",
    "print(f\"Conved Image TF:\\n{conv_image_tf.squeeze()}\")\n",
    "not_equals = (conv_image.flatten() != conv_image_tf.flatten())\n",
    "# assert np.allclose(conv_image.flatten(), conv_image_tf.flatten())\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=3)\n",
    "axs[0].imshow(image, cmap=\"gray\")\n",
    "axs[1].imshow(conv_image, cmap=\"gray\")\n",
    "axs[2].imshow(conv_image_tf.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "683035455952fa0c5c07396da2eac07ae1d76897e4164c7dcbe8556e60afc848"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('udemy_tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
